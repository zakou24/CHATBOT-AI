{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph import add_messages, StateGraph, END\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from uuid import uuid4\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tool = TavilySearch(max_results=4)\n",
    "\n",
    "tools = [search_tool]\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = model.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "async def model(state: State):\n",
    "    result = await llm_with_tools.ainvoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"messages\": [result], \n",
    "    }\n",
    "\n",
    "async def tools_router(state: State):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    if(hasattr(last_message, \"tool_calls\") and len(last_message.tool_calls) > 0):\n",
    "        return \"tool_node\"\n",
    "    else: \n",
    "        return END\n",
    "    \n",
    "# Can us ToolNode function instead\n",
    "async def tool_node(state):\n",
    "    \"\"\"Custom tool node that handles tool calls from the LLM.\"\"\"\n",
    "    # Get the tool calls from the last message\n",
    "    tool_calls = state[\"messages\"][-1].tool_calls\n",
    "    \n",
    "    # Initialize list to store tool messages\n",
    "    tool_messages = []\n",
    "    \n",
    "    # Process each tool call\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_id = tool_call[\"id\"]\n",
    "        \n",
    "        # Handle the search tool\n",
    "        if tool_name == \"tavily_search_results_json\":\n",
    "            # Execute the search tool with the provided arguments\n",
    "            search_results = await search_tool.ainvoke(tool_args)\n",
    "            \n",
    "            # Create a ToolMessage for this result\n",
    "            tool_message = ToolMessage(\n",
    "                content=str(search_results),\n",
    "                tool_call_id=tool_id,\n",
    "                name=tool_name\n",
    "            )\n",
    "            \n",
    "            tool_messages.append(tool_message)\n",
    "    \n",
    "    # Add the tool messages to the state\n",
    "    return {\"messages\": tool_messages}\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"model\", model)\n",
    "graph_builder.add_node(\"tool_node\", tool_node)\n",
    "graph_builder.set_entry_point(\"model\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\"model\", tools_router)\n",
    "graph_builder.add_edge(\"tool_node\", \"model\")\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='How are you doing?', additional_kwargs={}, response_metadata={}, id='cfc60098-453b-418e-90f2-9be5d35681a4'),\n",
       "  AIMessage(content='I am doing well, thank you for asking! I am ready to assist you with any questions or tasks you may have.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--affe2fa6-5eec-4cab-9f41-0949e30a243e-0', usage_metadata={'input_tokens': 1542, 'output_tokens': 25, 'total_tokens': 1567, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='My name is Zak', additional_kwargs={}, response_metadata={}, id='d7120e56-90c0-4dbe-be0b-76cd27ef0844'),\n",
       "  AIMessage(content=\"It's nice to meet you, Zak! How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--88aba067-dcc6-4816-a94b-e4b3cfebb5d8-0', usage_metadata={'input_tokens': 1573, 'output_tokens': 17, 'total_tokens': 1590, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='aaa57557-15e2-487e-a514-c4d85ac675dd'),\n",
       "  AIMessage(content='Your name is Zak.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--75ecb693-4115-44b0-9db2-f24694d23a89-0', usage_metadata={'input_tokens': 1597, 'output_tokens': 5, 'total_tokens': 1602, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 5\n",
    "    }\n",
    "}\n",
    "\n",
    "response = await graph.ainvoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is my name?\")], \n",
    "}, config=config)\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'text', 'text': \"Climate change, a pressing global crisis, refers to long-term shifts in temperatures and weather patterns. Primarily driven by human activities, especially the burning of fossil fuels, it leads to an increase in greenhouse gases trapping heat in the Earth's atmosphere.\", 'extras': {'signature': 'CikB0e2Kby4ubJj39JHFL1AqcS7L/nZMVBZllulk4HbX/l0kG2fN7HVvkgpYAdHtim8VeaxluxV3SdIRiJCC5dY1YR947m/gEgedBg9sT/b9WcjnBjbZKg0Axj3SlIZWiwJpQ8616A01uxeo99h0fOad4IOJRtwdbmkopPdlhOh48z8QjwqhAQHR7YpvFvSlRfQ9Eib/QhWalGh9y4Mf3AsuC/I9E60P9xK3bvbczfaBmINwoov30nYZ5CppWqPBTpweF5vKUy1PN3rt+WQbZutq88ASLaYc3o2N65ix0P7VJKeS4hNm/cTmjZs21oYJb0WOcYzpPMaUc7CfZzVyfjE8UNCGhES170cUE3Bwv1FV0ZRVF2GTUkJMntCZ45wk/PD9Tf7WwSux'}}] The consequences are far-reaching: rising sea levels, extreme weather events, disruptions to ecosystems, and threats to food security. Addressing this challenge requires urgent collective action, including transitioning to renewable energy sources, promoting sustainable practices, and implementing international policies to reduce carbon emissions. Our future depends on a concerted effort to mitigate these impacts and adapt to a changing planet."
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": 7\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use async for to iterate over the async generator\n",
    "async for event in graph.astream_events({\n",
    "    \"messages\": [HumanMessage(content=\"Give me 100 word essay on climate change\")]\n",
    "}, config=config, version=\"v2\"):\n",
    "    if event[\"event\"] == \"on_chat_model_stream\":\n",
    "        print(event[\"data\"][\"chunk\"].content, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
